{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install python-barcode\n!pip install check-digit-EAN13","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-11T08:22:42.449525Z","iopub.execute_input":"2024-04-11T08:22:42.450310Z","iopub.status.idle":"2024-04-11T08:23:12.102446Z","shell.execute_reply.started":"2024-04-11T08:22:42.450277Z","shell.execute_reply":"2024-04-11T08:23:12.101196Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting python-barcode\n  Obtaining dependency information for python-barcode from https://files.pythonhosted.org/packages/10/27/9b5c5bb1938d4e6b12f4c95f40ea905c11df3cd58e128e9305397b9a2697/python_barcode-0.15.1-py3-none-any.whl.metadata\n  Downloading python_barcode-0.15.1-py3-none-any.whl.metadata (2.3 kB)\nDownloading python_barcode-0.15.1-py3-none-any.whl (212 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: python-barcode\nSuccessfully installed python-barcode-0.15.1\nCollecting check-digit-EAN13\n  Downloading check_digit_EAN13-0.2.tar.gz (3.1 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: check-digit-EAN13\n  Building wheel for check-digit-EAN13 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for check-digit-EAN13: filename=check_digit_EAN13-0.2-py3-none-any.whl size=3395 sha256=b6c83c4a6adda1508a3a06aa92ce032b8b366767e4564e4370f3aa0aac5811f0\n  Stored in directory: /root/.cache/pip/wheels/28/39/0b/0272c58015e177a2303ba447d784efec4d356964d3d3e02890\nSuccessfully built check-digit-EAN13\nInstalling collected packages: check-digit-EAN13\nSuccessfully installed check-digit-EAN13-0.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Input, Conv2D, Add, ZeroPadding2D, UpSampling2D, Concatenate, MaxPooling2D, ZeroPadding2D, Lambda, Reshape, Flatten, Dense, concatenate\nfrom tensorflow.compat.v1.image import resize_nearest_neighbor, resize_bilinear\nfrom tensorflow.keras.layers import ReLU\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import MaxPool2D\nfrom tensorflow.keras.layers import Lambda\nfrom tensorflow.python.framework.ops import disable_eager_execution\nfrom tensorflow.keras.callbacks import *\nfrom functools import reduce\nfrom PIL import Image\nfrom matplotlib.colors import rgb_to_hsv, hsv_to_rgb\nimport cv2\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.utils import Sequence\nimport os \nimport cv2\nfrom barcode import EAN13, ISBN13\nfrom barcode.writer import ImageWriter\nfrom tqdm import tqdm\nfrom check_digit_EAN13.check_digit import get_check_digit","metadata":{"execution":{"iopub.status.busy":"2024-04-11T08:23:12.104525Z","iopub.execute_input":"2024-04-11T08:23:12.104856Z","iopub.status.idle":"2024-04-11T08:23:24.446333Z","shell.execute_reply.started":"2024-04-11T08:23:12.104828Z","shell.execute_reply":"2024-04-11T08:23:24.445462Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"IMAGE_HEIGHT = 160\nIMAGE_WIDTH = 320\nBATCH_SIZE = 256\ncount = 30000\npath = \"dataset_2\"","metadata":{"execution":{"iopub.status.busy":"2024-04-11T08:23:24.447371Z","iopub.execute_input":"2024-04-11T08:23:24.447937Z","iopub.status.idle":"2024-04-11T08:23:24.453097Z","shell.execute_reply.started":"2024-04-11T08:23:24.447908Z","shell.execute_reply":"2024-04-11T08:23:24.451895Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists(os.path.join(path, \"with_numbers\", \"images\")):\n    os.makedirs(os.path.join(path, \"with_numbers\", \"images\"))\nif not os.path.exists(os.path.join(path, \"without_numbers\", \"images\")):\n    os.makedirs(os.path.join(path, \"without_numbers\", \"images\"))","metadata":{"execution":{"iopub.status.busy":"2024-04-11T08:23:24.455975Z","iopub.execute_input":"2024-04-11T08:23:24.456546Z","iopub.status.idle":"2024-04-11T08:23:24.529343Z","shell.execute_reply.started":"2024-04-11T08:23:24.456508Z","shell.execute_reply":"2024-04-11T08:23:24.528033Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"for i in tqdm(range(count)):\n    random_code = np.random.randint(999999999999, 9999999999999, dtype=np.int64)\n    random_code = get_check_digit(random_code)\n    with open(\"{}/with_numbers/images/{}_{}_1.jpg\".format(path, str(random_code), str(i)), \"wb\") as file:\n        EAN13(str(random_code), writer=ImageWriter()).write(file)\n    # if i % 2 == 0:\n    image = cv2.imread(\"{}/with_numbers/images/{}_{}_1.jpg\".format(path, str(random_code), str(i)), cv2.IMREAD_GRAYSCALE)\n    image = np.asarray(image)[2:199, 63:460]\n    image = cv2.resize(image, (320, 160))\n    cv2.imwrite(\"{}/without_numbers/images/{}_{}_0.jpg\".format(path, str(random_code), str(i)), image)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T08:23:24.530954Z","iopub.execute_input":"2024-04-11T08:23:24.531415Z","iopub.status.idle":"2024-04-11T08:29:29.894161Z","shell.execute_reply.started":"2024-04-11T08:23:24.531335Z","shell.execute_reply":"2024-04-11T08:29:29.893186Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"100%|██████████| 30000/30000 [06:05<00:00, 82.11it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"class Datagenerator(Sequence):\n    def __init__(self, image_set_path, batch_size):\n        self.image_set_path = image_set_path\n        self.batch_size = batch_size\n        self.image_list = os.listdir(image_set_path)\n        print(len(self.image_list))\n\n    def __getitem__(self, index):\n        batch_input_list = self.image_list[self.batch_size * index: self.batch_size * (1 + index)]\n        \n        X = np.zeros((self.batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, 1))\n        Y = np.zeros((self.batch_size, 13, 10))\n        for i, image_name in enumerate(batch_input_list):\n            image = cv2.imread(os.path.join(self.image_set_path, image_name), cv2.IMREAD_GRAYSCALE)\n            image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n            image = np.expand_dims(image, -1)\n            image = image / 128\n            X[i] = image\n            Y[i] = self.encode_label(image_name.split(\"_\")[0])            \n        return X, Y\n\n    def __len__(self):\n        return len(self.image_list) // self.batch_size\n    \n    def encode_label(self, label):\n        OHE = np.zeros((13, 10))\n        for i, num in enumerate(label):\n            num = int(num)\n            OHE[i][num] = 1\n        return OHE","metadata":{"execution":{"iopub.status.busy":"2024-04-11T08:29:29.895569Z","iopub.execute_input":"2024-04-11T08:29:29.895898Z","iopub.status.idle":"2024-04-11T08:29:29.907160Z","shell.execute_reply.started":"2024-04-11T08:29:29.895868Z","shell.execute_reply":"2024-04-11T08:29:29.906076Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def custom_loss_tf(y_true, y_pred):\n    y_true = tf.reshape(y_true, (-1, 13, 10))\n    y_pred = tf.reshape(y_pred, (-1, 13, 10))\n    soft_pred = tf.math.softmax(y_pred, axis=-1)\n    cross_entropy = tf.losses.categorical_crossentropy(y_true=y_true, y_pred=soft_pred)\n    sum_loss = tf.math.reduce_sum(cross_entropy)\n    return sum_loss","metadata":{"execution":{"iopub.status.busy":"2024-04-11T08:29:29.908534Z","iopub.execute_input":"2024-04-11T08:29:29.908854Z","iopub.status.idle":"2024-04-11T08:29:29.918406Z","shell.execute_reply.started":"2024-04-11T08:29:29.908827Z","shell.execute_reply":"2024-04-11T08:29:29.917572Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def Conv2D_block(inputs, out_channels, kernel_size=(1, 1), strides=(1, 1), padding=\"same\"):\n    conv = Conv2D(out_channels, kernel_size, strides=strides, padding=padding, use_bias=False)(inputs)\n    bn = BatchNormalization()(conv)\n    relu_out = ReLU()(bn)\n\n    return relu_out","metadata":{"execution":{"iopub.status.busy":"2024-04-11T08:29:29.919757Z","iopub.execute_input":"2024-04-11T08:29:29.920010Z","iopub.status.idle":"2024-04-11T08:29:29.931572Z","shell.execute_reply.started":"2024-04-11T08:29:29.919987Z","shell.execute_reply":"2024-04-11T08:29:29.930624Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def Bottleneck(out_channels, shortcut=True, group=1, e=0.5, inputs=None):\n    if shortcut:\n        c_ = int(out_channels * e)\n        x1 = Conv2D_block(out_channels=c_, inputs=inputs)\n        x2 = Conv2D_block(out_channels=out_channels, inputs=x1, kernel_size=(3, 3), strides=(1, 1))\n        add = Add()([inputs, x2])\n        add = ReLU()(add)\n        return add\n    else:\n        c_ = int(out_channels * e)\n        x1 = Conv2D_block(out_channels=c_, inputs=inputs)\n        x2 = Conv2D_block(out_channels=out_channels, inputs=x1, kernel_size=(3, 3), strides=(1, 1))\n        return x2","metadata":{"execution":{"iopub.status.busy":"2024-04-11T08:29:29.932758Z","iopub.execute_input":"2024-04-11T08:29:29.933034Z","iopub.status.idle":"2024-04-11T08:29:29.941532Z","shell.execute_reply.started":"2024-04-11T08:29:29.933009Z","shell.execute_reply":"2024-04-11T08:29:29.940582Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def BottleneckCSP(out_channels, number=1, shortcut=True, group=1, e=0.5, inputs=None):\n    c_ = int(out_channels * e)\n    x1 = Conv2D_block(out_channels=c_, kernel_size=(1, 1), strides=(1, 1), inputs=inputs)\n\n    for _ in range(number):\n        x1 = Bottleneck(out_channels=c_, shortcut=shortcut, e=1.0, group=group, inputs=x1)\n    y2 = Conv2D_block(out_channels=c_, kernel_size=(1, 1), strides=(1, 1), inputs=inputs)\n\n    c = Concatenate()([x1, y2])\n    c = Conv2D_block(out_channels=2 * c_, kernel_size=(1, 1), strides=(1, 1), inputs=c)\n    return c","metadata":{"execution":{"iopub.status.busy":"2024-04-11T08:29:29.945218Z","iopub.execute_input":"2024-04-11T08:29:29.945522Z","iopub.status.idle":"2024-04-11T08:29:29.952917Z","shell.execute_reply.started":"2024-04-11T08:29:29.945496Z","shell.execute_reply":"2024-04-11T08:29:29.952008Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def SPP(c1, c2, k=(5, 9, 13), inputs=None):\n    c_ = c1 // 2  \n    x = Conv2D_block(out_channels=c_, kernel_size=(1, 1), strides=(1, 1), inputs=inputs)\n    x = Conv2D_block(out_channels=c2, kernel_size=(1, 1), strides=(1, 1), inputs=x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-04-11T08:29:29.954264Z","iopub.execute_input":"2024-04-11T08:29:29.954543Z","iopub.status.idle":"2024-04-11T08:29:29.963045Z","shell.execute_reply.started":"2024-04-11T08:29:29.954510Z","shell.execute_reply":"2024-04-11T08:29:29.962086Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def Dense_layer(num_class, inputs=None):\n    if len(inputs.shape) > 2:\n        inputs = Flatten()(inputs)\n\n    dense = Dense(num_class)(inputs)\n\n    return dense","metadata":{"execution":{"iopub.status.busy":"2024-04-11T08:29:29.964584Z","iopub.execute_input":"2024-04-11T08:29:29.964871Z","iopub.status.idle":"2024-04-11T08:29:29.972956Z","shell.execute_reply.started":"2024-04-11T08:29:29.964846Z","shell.execute_reply":"2024-04-11T08:29:29.971970Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def _create_model():\n    input_layer = Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 1),\n                            name=\"input\")\n\n    x0 = Conv2D_block(inputs=input_layer, out_channels=16, kernel_size=(3,3), strides=(2, 2))\n    x1 = Conv2D_block(inputs=x0, out_channels=32, kernel_size=(3, 3), strides=(2, 2))\n    x2 = BottleneckCSP(inputs=x1, number=1, out_channels=32, shortcut=True, group=1, e=0.5)\n    x3 = Conv2D_block(inputs=x2, out_channels=64, kernel_size=(3, 3), strides=(2, 2))\n    x4 = BottleneckCSP(inputs=x3, number=2, out_channels=64, shortcut=True, group=1, e=0.5)\n    x5 = Conv2D_block(inputs=x4, out_channels=128, kernel_size=(3, 3), strides=(2, 2))\n    x6 = BottleneckCSP(inputs=x5, number=3, out_channels=128, shortcut=True, group=1, e=0.5)    \n    x7 = Conv2D_block(inputs=x6, out_channels=256, kernel_size=(3, 3), strides=(1, 1))\n    x9 = BottleneckCSP(inputs=x7, number=1, out_channels=256, shortcut=True, group=1, e=0.5)\n    x111 = SPP(64, 32, inputs=x9)\n\n    # block 1\n    x10 = Conv2D_block(inputs=x111, out_channels=32, kernel_size=(3, 3), strides=(2, 2))\n    x10 = Dense_layer(130, x10)\n    \n    model = Model(input_layer, x10)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-04-11T08:29:29.974171Z","iopub.execute_input":"2024-04-11T08:29:29.974461Z","iopub.status.idle":"2024-04-11T08:29:29.988295Z","shell.execute_reply.started":"2024-04-11T08:29:29.974426Z","shell.execute_reply":"2024-04-11T08:29:29.987278Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = _create_model()\nmodel.summary()\nmodel.compile(optimizer=\"adam\", loss=custom_loss_tf, metrics=custom_loss_tf, run_eagerly=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T08:29:29.989596Z","iopub.execute_input":"2024-04-11T08:29:29.989909Z","iopub.status.idle":"2024-04-11T08:29:32.417288Z","shell.execute_reply.started":"2024-04-11T08:29:29.989884Z","shell.execute_reply":"2024-04-11T08:29:32.416296Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input (InputLayer)          [(None, 160, 320, 1)]        0         []                            \n                                                                                                  \n conv2d (Conv2D)             (None, 80, 160, 16)          144       ['input[0][0]']               \n                                                                                                  \n batch_normalization (Batch  (None, 80, 160, 16)          64        ['conv2d[0][0]']              \n Normalization)                                                                                   \n                                                                                                  \n re_lu (ReLU)                (None, 80, 160, 16)          0         ['batch_normalization[0][0]'] \n                                                                                                  \n conv2d_1 (Conv2D)           (None, 40, 80, 32)           4608      ['re_lu[0][0]']               \n                                                                                                  \n batch_normalization_1 (Bat  (None, 40, 80, 32)           128       ['conv2d_1[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n re_lu_1 (ReLU)              (None, 40, 80, 32)           0         ['batch_normalization_1[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_2 (Conv2D)           (None, 40, 80, 16)           512       ['re_lu_1[0][0]']             \n                                                                                                  \n batch_normalization_2 (Bat  (None, 40, 80, 16)           64        ['conv2d_2[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n re_lu_2 (ReLU)              (None, 40, 80, 16)           0         ['batch_normalization_2[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_3 (Conv2D)           (None, 40, 80, 16)           256       ['re_lu_2[0][0]']             \n                                                                                                  \n batch_normalization_3 (Bat  (None, 40, 80, 16)           64        ['conv2d_3[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n re_lu_3 (ReLU)              (None, 40, 80, 16)           0         ['batch_normalization_3[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_4 (Conv2D)           (None, 40, 80, 16)           2304      ['re_lu_3[0][0]']             \n                                                                                                  \n batch_normalization_4 (Bat  (None, 40, 80, 16)           64        ['conv2d_4[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n re_lu_4 (ReLU)              (None, 40, 80, 16)           0         ['batch_normalization_4[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_5 (Conv2D)           (None, 40, 80, 16)           512       ['re_lu_1[0][0]']             \n                                                                                                  \n add (Add)                   (None, 40, 80, 16)           0         ['re_lu_2[0][0]',             \n                                                                     're_lu_4[0][0]']             \n                                                                                                  \n batch_normalization_5 (Bat  (None, 40, 80, 16)           64        ['conv2d_5[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n re_lu_5 (ReLU)              (None, 40, 80, 16)           0         ['add[0][0]']                 \n                                                                                                  \n re_lu_6 (ReLU)              (None, 40, 80, 16)           0         ['batch_normalization_5[0][0]'\n                                                                    ]                             \n                                                                                                  \n concatenate (Concatenate)   (None, 40, 80, 32)           0         ['re_lu_5[0][0]',             \n                                                                     're_lu_6[0][0]']             \n                                                                                                  \n conv2d_6 (Conv2D)           (None, 40, 80, 32)           1024      ['concatenate[0][0]']         \n                                                                                                  \n batch_normalization_6 (Bat  (None, 40, 80, 32)           128       ['conv2d_6[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n re_lu_7 (ReLU)              (None, 40, 80, 32)           0         ['batch_normalization_6[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_7 (Conv2D)           (None, 20, 40, 64)           18432     ['re_lu_7[0][0]']             \n                                                                                                  \n batch_normalization_7 (Bat  (None, 20, 40, 64)           256       ['conv2d_7[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n re_lu_8 (ReLU)              (None, 20, 40, 64)           0         ['batch_normalization_7[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_8 (Conv2D)           (None, 20, 40, 32)           2048      ['re_lu_8[0][0]']             \n                                                                                                  \n batch_normalization_8 (Bat  (None, 20, 40, 32)           128       ['conv2d_8[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n re_lu_9 (ReLU)              (None, 20, 40, 32)           0         ['batch_normalization_8[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_9 (Conv2D)           (None, 20, 40, 32)           1024      ['re_lu_9[0][0]']             \n                                                                                                  \n batch_normalization_9 (Bat  (None, 20, 40, 32)           128       ['conv2d_9[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n re_lu_10 (ReLU)             (None, 20, 40, 32)           0         ['batch_normalization_9[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_10 (Conv2D)          (None, 20, 40, 32)           9216      ['re_lu_10[0][0]']            \n                                                                                                  \n batch_normalization_10 (Ba  (None, 20, 40, 32)           128       ['conv2d_10[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_11 (ReLU)             (None, 20, 40, 32)           0         ['batch_normalization_10[0][0]\n                                                                    ']                            \n                                                                                                  \n add_1 (Add)                 (None, 20, 40, 32)           0         ['re_lu_9[0][0]',             \n                                                                     're_lu_11[0][0]']            \n                                                                                                  \n re_lu_12 (ReLU)             (None, 20, 40, 32)           0         ['add_1[0][0]']               \n                                                                                                  \n conv2d_11 (Conv2D)          (None, 20, 40, 32)           1024      ['re_lu_12[0][0]']            \n                                                                                                  \n batch_normalization_11 (Ba  (None, 20, 40, 32)           128       ['conv2d_11[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_13 (ReLU)             (None, 20, 40, 32)           0         ['batch_normalization_11[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_12 (Conv2D)          (None, 20, 40, 32)           9216      ['re_lu_13[0][0]']            \n                                                                                                  \n batch_normalization_12 (Ba  (None, 20, 40, 32)           128       ['conv2d_12[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_14 (ReLU)             (None, 20, 40, 32)           0         ['batch_normalization_12[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_13 (Conv2D)          (None, 20, 40, 32)           2048      ['re_lu_8[0][0]']             \n                                                                                                  \n add_2 (Add)                 (None, 20, 40, 32)           0         ['re_lu_12[0][0]',            \n                                                                     're_lu_14[0][0]']            \n                                                                                                  \n batch_normalization_13 (Ba  (None, 20, 40, 32)           128       ['conv2d_13[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_15 (ReLU)             (None, 20, 40, 32)           0         ['add_2[0][0]']               \n                                                                                                  \n re_lu_16 (ReLU)             (None, 20, 40, 32)           0         ['batch_normalization_13[0][0]\n                                                                    ']                            \n                                                                                                  \n concatenate_1 (Concatenate  (None, 20, 40, 64)           0         ['re_lu_15[0][0]',            \n )                                                                   're_lu_16[0][0]']            \n                                                                                                  \n conv2d_14 (Conv2D)          (None, 20, 40, 64)           4096      ['concatenate_1[0][0]']       \n                                                                                                  \n batch_normalization_14 (Ba  (None, 20, 40, 64)           256       ['conv2d_14[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_17 (ReLU)             (None, 20, 40, 64)           0         ['batch_normalization_14[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_15 (Conv2D)          (None, 10, 20, 128)          73728     ['re_lu_17[0][0]']            \n                                                                                                  \n batch_normalization_15 (Ba  (None, 10, 20, 128)          512       ['conv2d_15[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_18 (ReLU)             (None, 10, 20, 128)          0         ['batch_normalization_15[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_16 (Conv2D)          (None, 10, 20, 64)           8192      ['re_lu_18[0][0]']            \n                                                                                                  \n batch_normalization_16 (Ba  (None, 10, 20, 64)           256       ['conv2d_16[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_19 (ReLU)             (None, 10, 20, 64)           0         ['batch_normalization_16[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_17 (Conv2D)          (None, 10, 20, 64)           4096      ['re_lu_19[0][0]']            \n                                                                                                  \n batch_normalization_17 (Ba  (None, 10, 20, 64)           256       ['conv2d_17[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_20 (ReLU)             (None, 10, 20, 64)           0         ['batch_normalization_17[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_18 (Conv2D)          (None, 10, 20, 64)           36864     ['re_lu_20[0][0]']            \n                                                                                                  \n batch_normalization_18 (Ba  (None, 10, 20, 64)           256       ['conv2d_18[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_21 (ReLU)             (None, 10, 20, 64)           0         ['batch_normalization_18[0][0]\n                                                                    ']                            \n                                                                                                  \n add_3 (Add)                 (None, 10, 20, 64)           0         ['re_lu_19[0][0]',            \n                                                                     're_lu_21[0][0]']            \n                                                                                                  \n re_lu_22 (ReLU)             (None, 10, 20, 64)           0         ['add_3[0][0]']               \n                                                                                                  \n conv2d_19 (Conv2D)          (None, 10, 20, 64)           4096      ['re_lu_22[0][0]']            \n                                                                                                  \n batch_normalization_19 (Ba  (None, 10, 20, 64)           256       ['conv2d_19[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_23 (ReLU)             (None, 10, 20, 64)           0         ['batch_normalization_19[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_20 (Conv2D)          (None, 10, 20, 64)           36864     ['re_lu_23[0][0]']            \n                                                                                                  \n batch_normalization_20 (Ba  (None, 10, 20, 64)           256       ['conv2d_20[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_24 (ReLU)             (None, 10, 20, 64)           0         ['batch_normalization_20[0][0]\n                                                                    ']                            \n                                                                                                  \n add_4 (Add)                 (None, 10, 20, 64)           0         ['re_lu_22[0][0]',            \n                                                                     're_lu_24[0][0]']            \n                                                                                                  \n re_lu_25 (ReLU)             (None, 10, 20, 64)           0         ['add_4[0][0]']               \n                                                                                                  \n conv2d_21 (Conv2D)          (None, 10, 20, 64)           4096      ['re_lu_25[0][0]']            \n                                                                                                  \n batch_normalization_21 (Ba  (None, 10, 20, 64)           256       ['conv2d_21[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_26 (ReLU)             (None, 10, 20, 64)           0         ['batch_normalization_21[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_22 (Conv2D)          (None, 10, 20, 64)           36864     ['re_lu_26[0][0]']            \n                                                                                                  \n batch_normalization_22 (Ba  (None, 10, 20, 64)           256       ['conv2d_22[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_27 (ReLU)             (None, 10, 20, 64)           0         ['batch_normalization_22[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_23 (Conv2D)          (None, 10, 20, 64)           8192      ['re_lu_18[0][0]']            \n                                                                                                  \n add_5 (Add)                 (None, 10, 20, 64)           0         ['re_lu_25[0][0]',            \n                                                                     're_lu_27[0][0]']            \n                                                                                                  \n batch_normalization_23 (Ba  (None, 10, 20, 64)           256       ['conv2d_23[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_28 (ReLU)             (None, 10, 20, 64)           0         ['add_5[0][0]']               \n                                                                                                  \n re_lu_29 (ReLU)             (None, 10, 20, 64)           0         ['batch_normalization_23[0][0]\n                                                                    ']                            \n                                                                                                  \n concatenate_2 (Concatenate  (None, 10, 20, 128)          0         ['re_lu_28[0][0]',            \n )                                                                   're_lu_29[0][0]']            \n                                                                                                  \n conv2d_24 (Conv2D)          (None, 10, 20, 128)          16384     ['concatenate_2[0][0]']       \n                                                                                                  \n batch_normalization_24 (Ba  (None, 10, 20, 128)          512       ['conv2d_24[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_30 (ReLU)             (None, 10, 20, 128)          0         ['batch_normalization_24[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_25 (Conv2D)          (None, 10, 20, 256)          294912    ['re_lu_30[0][0]']            \n                                                                                                  \n batch_normalization_25 (Ba  (None, 10, 20, 256)          1024      ['conv2d_25[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_31 (ReLU)             (None, 10, 20, 256)          0         ['batch_normalization_25[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_26 (Conv2D)          (None, 10, 20, 128)          32768     ['re_lu_31[0][0]']            \n                                                                                                  \n batch_normalization_26 (Ba  (None, 10, 20, 128)          512       ['conv2d_26[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_32 (ReLU)             (None, 10, 20, 128)          0         ['batch_normalization_26[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_27 (Conv2D)          (None, 10, 20, 128)          16384     ['re_lu_32[0][0]']            \n                                                                                                  \n batch_normalization_27 (Ba  (None, 10, 20, 128)          512       ['conv2d_27[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_33 (ReLU)             (None, 10, 20, 128)          0         ['batch_normalization_27[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_28 (Conv2D)          (None, 10, 20, 128)          147456    ['re_lu_33[0][0]']            \n                                                                                                  \n batch_normalization_28 (Ba  (None, 10, 20, 128)          512       ['conv2d_28[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_34 (ReLU)             (None, 10, 20, 128)          0         ['batch_normalization_28[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_29 (Conv2D)          (None, 10, 20, 128)          32768     ['re_lu_31[0][0]']            \n                                                                                                  \n add_6 (Add)                 (None, 10, 20, 128)          0         ['re_lu_32[0][0]',            \n                                                                     're_lu_34[0][0]']            \n                                                                                                  \n batch_normalization_29 (Ba  (None, 10, 20, 128)          512       ['conv2d_29[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_35 (ReLU)             (None, 10, 20, 128)          0         ['add_6[0][0]']               \n                                                                                                  \n re_lu_36 (ReLU)             (None, 10, 20, 128)          0         ['batch_normalization_29[0][0]\n                                                                    ']                            \n                                                                                                  \n concatenate_3 (Concatenate  (None, 10, 20, 256)          0         ['re_lu_35[0][0]',            \n )                                                                   're_lu_36[0][0]']            \n                                                                                                  \n conv2d_30 (Conv2D)          (None, 10, 20, 256)          65536     ['concatenate_3[0][0]']       \n                                                                                                  \n batch_normalization_30 (Ba  (None, 10, 20, 256)          1024      ['conv2d_30[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_37 (ReLU)             (None, 10, 20, 256)          0         ['batch_normalization_30[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_31 (Conv2D)          (None, 10, 20, 32)           8192      ['re_lu_37[0][0]']            \n                                                                                                  \n batch_normalization_31 (Ba  (None, 10, 20, 32)           128       ['conv2d_31[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_38 (ReLU)             (None, 10, 20, 32)           0         ['batch_normalization_31[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_32 (Conv2D)          (None, 10, 20, 32)           1024      ['re_lu_38[0][0]']            \n                                                                                                  \n batch_normalization_32 (Ba  (None, 10, 20, 32)           128       ['conv2d_32[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_39 (ReLU)             (None, 10, 20, 32)           0         ['batch_normalization_32[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_33 (Conv2D)          (None, 5, 10, 32)            9216      ['re_lu_39[0][0]']            \n                                                                                                  \n batch_normalization_33 (Ba  (None, 5, 10, 32)            128       ['conv2d_33[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_40 (ReLU)             (None, 5, 10, 32)            0         ['batch_normalization_33[0][0]\n                                                                    ']                            \n                                                                                                  \n flatten (Flatten)           (None, 1600)                 0         ['re_lu_40[0][0]']            \n                                                                                                  \n dense (Dense)               (None, 130)                  208130    ['flatten[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 1111634 (4.24 MB)\nTrainable params: 1106930 (4.22 MB)\nNon-trainable params: 4704 (18.38 KB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"data_generator = Datagenerator(\"/kaggle/working/dataset_2/without_numbers/images\", BATCH_SIZE) \ncallbacks_ckpt = ModelCheckpoint(\"model_{epoch:03d}.h5\", save_freq=10)\nimage_batch_shape = (BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, 1)\nlabel_batch_shape = (BATCH_SIZE, 13, 10)\ntf_train_generator = tf.data.Dataset.from_generator(lambda: map(tuple, data_generator), \n                                                    (tf.float32, tf.float32),\n                                                    (image_batch_shape, label_batch_shape))\ntf_train_generator = tf_train_generator.prefetch(buffer_size=tf.data.AUTOTUNE).cache()","metadata":{"execution":{"iopub.status.busy":"2024-04-11T08:29:32.418490Z","iopub.execute_input":"2024-04-11T08:29:32.418775Z","iopub.status.idle":"2024-04-11T08:29:32.497873Z","shell.execute_reply.started":"2024-04-11T08:29:32.418749Z","shell.execute_reply":"2024-04-11T08:29:32.496834Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"30000\n","output_type":"stream"}]},{"cell_type":"code","source":"tf.config.run_functions_eagerly(True)\nmodel.fit(tf_train_generator, epochs=70, callbacks=[callbacks_ckpt], verbose=1)\nmodel.save(\"last_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-04-11T08:29:32.499113Z","iopub.execute_input":"2024-04-11T08:29:32.499432Z","iopub.status.idle":"2024-04-11T09:30:18.903035Z","shell.execute_reply.started":"2024-04-11T08:29:32.499407Z","shell.execute_reply":"2024-04-11T09:30:18.902059Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/70\n      9/Unknown - 8s 525ms/step - loss: 8122.6528 - custom_loss_tf: 8122.6528","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"117/117 [==============================] - 67s 541ms/step - loss: 3207.8750 - custom_loss_tf: 3207.8750\nEpoch 2/70\n117/117 [==============================] - 52s 445ms/step - loss: 77.8751 - custom_loss_tf: 77.8751\nEpoch 3/70\n117/117 [==============================] - 52s 443ms/step - loss: 21.7415 - custom_loss_tf: 21.7415\nEpoch 4/70\n117/117 [==============================] - 52s 443ms/step - loss: 11.4298 - custom_loss_tf: 11.4298\nEpoch 5/70\n117/117 [==============================] - 51s 439ms/step - loss: 7.1930 - custom_loss_tf: 7.1930\nEpoch 6/70\n117/117 [==============================] - 52s 443ms/step - loss: 4.9809 - custom_loss_tf: 4.9809\nEpoch 7/70\n117/117 [==============================] - 51s 439ms/step - loss: 3.6647 - custom_loss_tf: 3.6647\nEpoch 8/70\n117/117 [==============================] - 52s 441ms/step - loss: 2.8123 - custom_loss_tf: 2.8123\nEpoch 9/70\n117/117 [==============================] - 52s 444ms/step - loss: 2.2262 - custom_loss_tf: 2.2262\nEpoch 10/70\n117/117 [==============================] - 52s 445ms/step - loss: 1.8046 - custom_loss_tf: 1.8046\nEpoch 11/70\n117/117 [==============================] - 51s 440ms/step - loss: 1.4907 - custom_loss_tf: 1.4907\nEpoch 12/70\n117/117 [==============================] - 52s 447ms/step - loss: 1.2502 - custom_loss_tf: 1.2502\nEpoch 13/70\n117/117 [==============================] - 52s 445ms/step - loss: 1.0619 - custom_loss_tf: 1.0619\nEpoch 14/70\n117/117 [==============================] - 52s 441ms/step - loss: 0.9115 - custom_loss_tf: 0.9115\nEpoch 15/70\n117/117 [==============================] - 52s 448ms/step - loss: 0.7894 - custom_loss_tf: 0.7894\nEpoch 16/70\n117/117 [==============================] - 52s 445ms/step - loss: 0.6890 - custom_loss_tf: 0.6890\nEpoch 17/70\n117/117 [==============================] - 52s 445ms/step - loss: 0.6054 - custom_loss_tf: 0.6054\nEpoch 18/70\n117/117 [==============================] - 52s 445ms/step - loss: 0.5351 - custom_loss_tf: 0.5351\nEpoch 19/70\n117/117 [==============================] - 52s 445ms/step - loss: 0.4754 - custom_loss_tf: 0.4754\nEpoch 20/70\n117/117 [==============================] - 52s 444ms/step - loss: 0.4243 - custom_loss_tf: 0.4243\nEpoch 21/70\n117/117 [==============================] - 52s 445ms/step - loss: 0.3802 - custom_loss_tf: 0.3802\nEpoch 22/70\n117/117 [==============================] - 52s 448ms/step - loss: 0.3420 - custom_loss_tf: 0.3420\nEpoch 23/70\n117/117 [==============================] - 52s 444ms/step - loss: 0.3086 - custom_loss_tf: 0.3086\nEpoch 24/70\n117/117 [==============================] - 51s 440ms/step - loss: 0.2793 - custom_loss_tf: 0.2793\nEpoch 25/70\n117/117 [==============================] - 51s 440ms/step - loss: 0.2534 - custom_loss_tf: 0.2534\nEpoch 26/70\n117/117 [==============================] - 52s 444ms/step - loss: 0.2306 - custom_loss_tf: 0.2306\nEpoch 27/70\n117/117 [==============================] - 52s 444ms/step - loss: 0.2102 - custom_loss_tf: 0.2102\nEpoch 28/70\n117/117 [==============================] - 52s 445ms/step - loss: 0.1920 - custom_loss_tf: 0.1920\nEpoch 29/70\n117/117 [==============================] - 52s 442ms/step - loss: 0.1757 - custom_loss_tf: 0.1757\nEpoch 30/70\n117/117 [==============================] - 52s 442ms/step - loss: 0.1611 - custom_loss_tf: 0.1611\nEpoch 31/70\n117/117 [==============================] - 51s 436ms/step - loss: 0.1480 - custom_loss_tf: 0.1480\nEpoch 32/70\n117/117 [==============================] - 52s 445ms/step - loss: 0.1361 - custom_loss_tf: 0.1361\nEpoch 33/70\n117/117 [==============================] - 52s 445ms/step - loss: 0.1253 - custom_loss_tf: 0.1253\nEpoch 34/70\n117/117 [==============================] - 51s 438ms/step - loss: 0.1155 - custom_loss_tf: 0.1155\nEpoch 35/70\n117/117 [==============================] - 51s 438ms/step - loss: 0.1066 - custom_loss_tf: 0.1066\nEpoch 36/70\n117/117 [==============================] - 51s 434ms/step - loss: 0.0985 - custom_loss_tf: 0.0985\nEpoch 37/70\n117/117 [==============================] - 51s 435ms/step - loss: 0.0911 - custom_loss_tf: 0.0911\nEpoch 38/70\n117/117 [==============================] - 52s 443ms/step - loss: 0.0844 - custom_loss_tf: 0.0844\nEpoch 39/70\n117/117 [==============================] - 54s 459ms/step - loss: 0.0782 - custom_loss_tf: 0.0782\nEpoch 40/70\n117/117 [==============================] - 52s 447ms/step - loss: 0.0725 - custom_loss_tf: 0.0725\nEpoch 41/70\n117/117 [==============================] - 51s 436ms/step - loss: 0.0673 - custom_loss_tf: 0.0673\nEpoch 42/70\n117/117 [==============================] - 51s 435ms/step - loss: 0.0625 - custom_loss_tf: 0.0625\nEpoch 43/70\n117/117 [==============================] - 51s 438ms/step - loss: 0.0580 - custom_loss_tf: 0.0580\nEpoch 44/70\n117/117 [==============================] - 51s 434ms/step - loss: 0.0540 - custom_loss_tf: 0.0540\nEpoch 45/70\n117/117 [==============================] - 51s 437ms/step - loss: 0.0502 - custom_loss_tf: 0.0502\nEpoch 46/70\n117/117 [==============================] - 51s 437ms/step - loss: 0.0467 - custom_loss_tf: 0.0467\nEpoch 47/70\n117/117 [==============================] - 50s 432ms/step - loss: 0.0435 - custom_loss_tf: 0.0435\nEpoch 48/70\n117/117 [==============================] - 51s 433ms/step - loss: 0.0405 - custom_loss_tf: 0.0405\nEpoch 49/70\n117/117 [==============================] - 51s 434ms/step - loss: 0.0378 - custom_loss_tf: 0.0378\nEpoch 50/70\n117/117 [==============================] - 51s 440ms/step - loss: 0.0352 - custom_loss_tf: 0.0352\nEpoch 51/70\n117/117 [==============================] - 51s 432ms/step - loss: 0.0329 - custom_loss_tf: 0.0329\nEpoch 52/70\n117/117 [==============================] - 51s 437ms/step - loss: 0.0307 - custom_loss_tf: 0.0307\nEpoch 53/70\n117/117 [==============================] - 51s 435ms/step - loss: 0.0286 - custom_loss_tf: 0.0286\nEpoch 54/70\n117/117 [==============================] - 51s 434ms/step - loss: 0.0267 - custom_loss_tf: 0.0267\nEpoch 55/70\n117/117 [==============================] - 51s 436ms/step - loss: 0.0250 - custom_loss_tf: 0.0250\nEpoch 56/70\n117/117 [==============================] - 51s 437ms/step - loss: 0.0233 - custom_loss_tf: 0.0233\nEpoch 57/70\n117/117 [==============================] - 51s 434ms/step - loss: 0.0218 - custom_loss_tf: 0.0218\nEpoch 58/70\n117/117 [==============================] - 51s 436ms/step - loss: 0.0204 - custom_loss_tf: 0.0204\nEpoch 59/70\n117/117 [==============================] - 51s 438ms/step - loss: 0.0191 - custom_loss_tf: 0.0191\nEpoch 60/70\n117/117 [==============================] - 51s 434ms/step - loss: 0.0178 - custom_loss_tf: 0.0178\nEpoch 61/70\n117/117 [==============================] - 51s 435ms/step - loss: 0.0167 - custom_loss_tf: 0.0167\nEpoch 62/70\n117/117 [==============================] - 51s 436ms/step - loss: 0.0156 - custom_loss_tf: 0.0156\nEpoch 63/70\n117/117 [==============================] - 51s 437ms/step - loss: 0.0146 - custom_loss_tf: 0.0146\nEpoch 64/70\n117/117 [==============================] - 51s 432ms/step - loss: 0.0137 - custom_loss_tf: 0.0137\nEpoch 65/70\n117/117 [==============================] - 51s 433ms/step - loss: 0.0128 - custom_loss_tf: 0.0128\nEpoch 66/70\n117/117 [==============================] - 51s 434ms/step - loss: 0.0120 - custom_loss_tf: 0.0120\nEpoch 67/70\n117/117 [==============================] - 50s 428ms/step - loss: 0.0112 - custom_loss_tf: 0.0112\nEpoch 68/70\n117/117 [==============================] - 51s 431ms/step - loss: 0.0105 - custom_loss_tf: 0.0105\nEpoch 69/70\n117/117 [==============================] - 51s 433ms/step - loss: 0.0098 - custom_loss_tf: 0.0098\nEpoch 70/70\n117/117 [==============================] - 51s 435ms/step - loss: 0.0092 - custom_loss_tf: 0.0092\n","output_type":"stream"}]},{"cell_type":"code","source":"path = \"test\"\nif not os.path.exists(os.path.join(\"test\", \"with_numbers\", \"images\")):\n    os.makedirs(os.path.join(\"test\", \"with_numbers\", \"images\"))\nif not os.path.exists(os.path.join(\"test\", \"without_numbers\", \"   images\")):\n    os.makedirs(os.path.join(\"test\", \"without_numbers\", \"images\"))\ncount = 30\nfor i in tqdm(range(count)):\n    random_code = np.random.randint(999999999999, 9999999999999, dtype=np.int64)\n    random_code = get_check_digit(random_code)\n    with open(\"{}/with_numbers/images/{}_{}_1.jpg\".format(path, str(random_code), str(i)), \"wb\") as file:\n        EAN13(str(random_code), writer=ImageWriter()).write(file)\n    # if i % 2 == 0:\n    image = cv2.imread(\"{}/with_numbers/images/{}_{}_1.jpg\".format(path, str(random_code), str(i)), cv2.IMREAD_GRAYSCALE)\n    image = np.asarray(image)[2:199, 63:460]\n    image = cv2.resize(image, (320, 160))\n    cv2.imwrite(\"{}/without_numbers/images/{}_{}_0.jpg\".format(path, str(random_code), str(i)), image)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T09:30:18.904407Z","iopub.execute_input":"2024-04-11T09:30:18.904700Z","iopub.status.idle":"2024-04-11T09:30:22.443638Z","shell.execute_reply.started":"2024-04-11T09:30:18.904674Z","shell.execute_reply":"2024-04-11T09:30:22.442694Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"100%|██████████| 300/300 [00:03<00:00, 85.11it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def filter_predicitons_tf(y_pred):\n    barcode_list = []\n    y_pred = np.reshape(y_pred, (-1, 13, 10))\n#     print(tf.make_ndarray(y_pred))\n    pred_idx = np.argmax(y_pred, axis=-1)\n    for pred_barcode in pred_idx:\n        barcode = \"\"\n        for num in pred_barcode:\n            barcode += str(num)\n        barcode_list.append(barcode)\n    return barcode_list\n\ndef humming_distance(string_1, string_2):\n    i = 0\n    count = 0\n    while i < len(string_1):\n        if string_1[i] != string_2[i]:\n            count += 1\n        i += 1\n    return count","metadata":{"execution":{"iopub.status.busy":"2024-04-11T09:30:22.445009Z","iopub.execute_input":"2024-04-11T09:30:22.445425Z","iopub.status.idle":"2024-04-11T09:30:22.453389Z","shell.execute_reply.started":"2024-04-11T09:30:22.445389Z","shell.execute_reply":"2024-04-11T09:30:22.452175Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"res_count = 0\nfor image_name in os.listdir(\"/kaggle/working/test/without_numbers/images\"):\n    image = cv2.imread(\"/kaggle/working/test/without_numbers/images/\"+ image_name, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n    image = np.expand_dims(image, -1)\n    image = image / 128\n    image = np.asarray([image])\n    res = model.predict([image])\n    res = filter_predicitons_tf(res)\n#     print(image_name.split(\"_\")[0], res[0])\n    dist = humming_distance(image_name.split(\"_\")[0], res[0])\n    if dist == 0:\n        res_count = res_count + 1\n    print(image_name, \" : \", res[0], \" : \", dist)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T09:30:22.454625Z","iopub.execute_input":"2024-04-11T09:30:22.454979Z","iopub.status.idle":"2024-04-11T09:31:00.972790Z","shell.execute_reply.started":"2024-04-11T09:30:22.454953Z","shell.execute_reply":"2024-04-11T09:31:00.971837Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 258ms/step\n6190328652884_285_0.jpg  :  6190328652884  :  0\n1/1 [==============================] - 0s 83ms/step\n7715549180450_121_0.jpg  :  7715549180450  :  0\n1/1 [==============================] - 0s 84ms/step\n5182578540142_0_0.jpg  :  5182578540142  :  0\n1/1 [==============================] - 0s 85ms/step\n8653773412376_39_0.jpg  :  8653773412376  :  0\n1/1 [==============================] - 0s 86ms/step\n4821317071547_139_0.jpg  :  4821317071547  :  0\n1/1 [==============================] - 0s 86ms/step\n2195916935251_40_0.jpg  :  2195916935251  :  0\n1/1 [==============================] - 0s 88ms/step\n7363760614171_191_0.jpg  :  7363760614171  :  0\n1/1 [==============================] - 0s 89ms/step\n2550492630479_171_0.jpg  :  2550492630479  :  0\n1/1 [==============================] - 0s 85ms/step\n5836141563679_50_0.jpg  :  5836141563679  :  0\n1/1 [==============================] - 0s 84ms/step\n4980833482715_272_0.jpg  :  4980833482715  :  0\n1/1 [==============================] - 0s 87ms/step\n1386559493500_30_0.jpg  :  1386559493500  :  0\n1/1 [==============================] - 0s 92ms/step\n5716256639073_25_0.jpg  :  5716256639073  :  0\n1/1 [==============================] - 0s 88ms/step\n2606088291408_8_0.jpg  :  2606088291408  :  0\n1/1 [==============================] - 0s 86ms/step\n7869557645927_107_0.jpg  :  7869557645927  :  0\n1/1 [==============================] - 0s 85ms/step\n9350416114657_244_0.jpg  :  9350416114657  :  0\n1/1 [==============================] - 0s 85ms/step\n5032014273670_9_0.jpg  :  5032014273670  :  0\n1/1 [==============================] - 0s 85ms/step\n7877855671739_144_0.jpg  :  7877855671739  :  0\n1/1 [==============================] - 0s 86ms/step\n3089933229570_151_0.jpg  :  3089933229570  :  0\n1/1 [==============================] - 0s 88ms/step\n6312050799808_234_0.jpg  :  6312050799808  :  0\n1/1 [==============================] - 0s 87ms/step\n8234596631146_55_0.jpg  :  8234596631146  :  0\n1/1 [==============================] - 0s 88ms/step\n4951457057504_68_0.jpg  :  4951457057504  :  0\n1/1 [==============================] - 0s 88ms/step\n3480202226779_43_0.jpg  :  3480202226779  :  0\n1/1 [==============================] - 0s 86ms/step\n6428346054602_98_0.jpg  :  6428346054602  :  0\n1/1 [==============================] - 0s 85ms/step\n1889671629333_130_0.jpg  :  1889671629333  :  0\n1/1 [==============================] - 0s 91ms/step\n9772595444415_122_0.jpg  :  9772595444415  :  0\n1/1 [==============================] - 0s 88ms/step\n8623193488886_217_0.jpg  :  8623193488886  :  0\n1/1 [==============================] - 0s 85ms/step\n7566529329945_279_0.jpg  :  7566529329945  :  0\n1/1 [==============================] - 0s 87ms/step\n2401057192768_14_0.jpg  :  2401057192768  :  0\n1/1 [==============================] - 0s 90ms/step\n8121076885635_183_0.jpg  :  8121076885635  :  0\n1/1 [==============================] - 0s 89ms/step\n6350125010830_123_0.jpg  :  6350125010830  :  0\n1/1 [==============================] - 0s 87ms/step\n4394738982421_145_0.jpg  :  4394738982421  :  0\n1/1 [==============================] - 0s 87ms/step\n7612897101185_225_0.jpg  :  7612897101185  :  0\n1/1 [==============================] - 0s 88ms/step\n8691702221590_288_0.jpg  :  8691702221590  :  0\n1/1 [==============================] - 0s 97ms/step\n2185199529605_170_0.jpg  :  2185199529605  :  0\n1/1 [==============================] - 0s 86ms/step\n9179777301922_116_0.jpg  :  9179777301922  :  0\n1/1 [==============================] - 0s 90ms/step\n5377835872429_240_0.jpg  :  5377835872429  :  0\n1/1 [==============================] - 0s 91ms/step\n9126123106526_156_0.jpg  :  9126123106526  :  0\n1/1 [==============================] - 0s 86ms/step\n8989505388009_229_0.jpg  :  8989505388009  :  0\n1/1 [==============================] - 0s 88ms/step\n5756052439866_94_0.jpg  :  5756052439866  :  0\n1/1 [==============================] - 0s 89ms/step\n3814866949772_221_0.jpg  :  3814866949772  :  0\n1/1 [==============================] - 0s 88ms/step\n6821470010863_56_0.jpg  :  6821470010863  :  0\n1/1 [==============================] - 0s 86ms/step\n5180738989138_281_0.jpg  :  5180738989138  :  0\n1/1 [==============================] - 0s 83ms/step\n5480075370294_261_0.jpg  :  5480075370294  :  0\n1/1 [==============================] - 0s 88ms/step\n2332172936237_282_0.jpg  :  2332172936237  :  0\n1/1 [==============================] - 0s 88ms/step\n6454332427556_47_0.jpg  :  6454332427556  :  0\n1/1 [==============================] - 0s 84ms/step\n8953872914208_100_0.jpg  :  8953872914208  :  0\n1/1 [==============================] - 0s 85ms/step\n2565486604848_233_0.jpg  :  2565486604848  :  0\n1/1 [==============================] - 0s 86ms/step\n2118985388629_46_0.jpg  :  2118985388629  :  0\n1/1 [==============================] - 0s 91ms/step\n2009516850541_269_0.jpg  :  2009516850541  :  0\n1/1 [==============================] - 0s 90ms/step\n9778690032663_197_0.jpg  :  9778690032663  :  0\n1/1 [==============================] - 0s 89ms/step\n8887338151282_294_0.jpg  :  8887338151282  :  0\n1/1 [==============================] - 0s 84ms/step\n3505431808487_36_0.jpg  :  3505431808487  :  0\n1/1 [==============================] - 0s 86ms/step\n4112140111501_256_0.jpg  :  4112140111501  :  0\n1/1 [==============================] - 0s 85ms/step\n8929501032193_243_0.jpg  :  8929501032193  :  0\n1/1 [==============================] - 0s 85ms/step\n8279997025538_283_0.jpg  :  8279997025538  :  0\n1/1 [==============================] - 0s 84ms/step\n9452190032087_140_0.jpg  :  9452190032087  :  0\n1/1 [==============================] - 0s 87ms/step\n3430921787426_87_0.jpg  :  3430921787426  :  0\n1/1 [==============================] - 0s 87ms/step\n3755569497231_22_0.jpg  :  3755569497231  :  0\n1/1 [==============================] - 0s 83ms/step\n1143177516888_131_0.jpg  :  1143177516888  :  0\n1/1 [==============================] - 0s 89ms/step\n1767492025100_162_0.jpg  :  1767492025100  :  0\n1/1 [==============================] - 0s 87ms/step\n4039330215866_58_0.jpg  :  4039330215866  :  0\n1/1 [==============================] - 0s 84ms/step\n5705283385206_117_0.jpg  :  5705283385206  :  0\n1/1 [==============================] - 0s 84ms/step\n2709642091947_13_0.jpg  :  2709642091947  :  0\n1/1 [==============================] - 0s 85ms/step\n3926562561179_215_0.jpg  :  3926562561179  :  0\n1/1 [==============================] - 0s 85ms/step\n3815818204734_268_0.jpg  :  3815818204734  :  0\n1/1 [==============================] - 0s 84ms/step\n2984814887249_254_0.jpg  :  2984814887249  :  0\n1/1 [==============================] - 0s 92ms/step\n8011678518140_257_0.jpg  :  8011678518140  :  0\n1/1 [==============================] - 0s 87ms/step\n8466777841765_90_0.jpg  :  8466777841765  :  0\n1/1 [==============================] - 0s 84ms/step\n8896321698970_258_0.jpg  :  8896321698970  :  0\n1/1 [==============================] - 0s 88ms/step\n4600531157646_236_0.jpg  :  4600531157646  :  0\n1/1 [==============================] - 0s 88ms/step\n4631048324801_182_0.jpg  :  4631048324801  :  0\n1/1 [==============================] - 0s 84ms/step\n4167018158614_148_0.jpg  :  4167018158614  :  0\n1/1 [==============================] - 0s 87ms/step\n2784105530348_195_0.jpg  :  2784105530348  :  0\n1/1 [==============================] - 0s 87ms/step\n6451889151620_230_0.jpg  :  6451889151620  :  0\n1/1 [==============================] - 0s 84ms/step\n7517019714383_181_0.jpg  :  7517019714383  :  0\n1/1 [==============================] - 0s 86ms/step\n9196413684829_99_0.jpg  :  9196413684829  :  0\n1/1 [==============================] - 0s 87ms/step\n7836032616161_136_0.jpg  :  7836032616161  :  0\n1/1 [==============================] - 0s 86ms/step\n2552683659436_128_0.jpg  :  2552683659436  :  0\n1/1 [==============================] - 0s 85ms/step\n9202965019597_167_0.jpg  :  9202965019597  :  0\n1/1 [==============================] - 0s 85ms/step\n1712843528021_129_0.jpg  :  1712843528021  :  0\n1/1 [==============================] - 0s 86ms/step\n2447597976178_127_0.jpg  :  2447597976178  :  0\n1/1 [==============================] - 0s 83ms/step\n1323531921606_189_0.jpg  :  1323531921606  :  0\n1/1 [==============================] - 0s 85ms/step\n3514432277703_73_0.jpg  :  3514432277703  :  0\n1/1 [==============================] - 0s 84ms/step\n6531010747653_118_0.jpg  :  6531010747653  :  0\n1/1 [==============================] - 0s 84ms/step\n8370948466421_292_0.jpg  :  8370948466421  :  0\n1/1 [==============================] - 0s 87ms/step\n1868211133318_59_0.jpg  :  1868211133318  :  0\n1/1 [==============================] - 0s 88ms/step\n6172537082904_102_0.jpg  :  6172537082904  :  0\n1/1 [==============================] - 0s 86ms/step\n7917841678387_95_0.jpg  :  7917841678387  :  0\n1/1 [==============================] - 0s 85ms/step\n4880163590084_37_0.jpg  :  4880163590084  :  0\n1/1 [==============================] - 0s 86ms/step\n4537202781100_65_0.jpg  :  4537202781100  :  0\n1/1 [==============================] - 0s 86ms/step\n6584176695139_214_0.jpg  :  6584176695139  :  0\n1/1 [==============================] - 0s 83ms/step\n8931270470892_41_0.jpg  :  8931270470892  :  0\n1/1 [==============================] - 0s 86ms/step\n4791623430416_64_0.jpg  :  4791623430416  :  0\n1/1 [==============================] - 0s 85ms/step\n5528843744387_271_0.jpg  :  5528843744387  :  0\n1/1 [==============================] - 0s 87ms/step\n2814790200421_29_0.jpg  :  2814790200421  :  0\n1/1 [==============================] - 0s 86ms/step\n8663630601140_199_0.jpg  :  8663630601140  :  0\n1/1 [==============================] - 0s 85ms/step\n9638189908407_299_0.jpg  :  9638189908407  :  0\n1/1 [==============================] - 0s 85ms/step\n8661057086595_255_0.jpg  :  8661057086595  :  0\n1/1 [==============================] - 0s 86ms/step\n1600205143916_103_0.jpg  :  1600205143916  :  0\n1/1 [==============================] - 0s 85ms/step\n1033339603832_45_0.jpg  :  1033339603832  :  0\n1/1 [==============================] - 0s 85ms/step\n6614798134119_174_0.jpg  :  6614798134119  :  0\n1/1 [==============================] - 0s 83ms/step\n5118682842001_33_0.jpg  :  5118682842001  :  0\n1/1 [==============================] - 0s 87ms/step\n4540897438754_241_0.jpg  :  4540897438754  :  0\n1/1 [==============================] - 0s 86ms/step\n7978809118659_251_0.jpg  :  7978809118659  :  0\n1/1 [==============================] - 0s 86ms/step\n1685401513480_203_0.jpg  :  1685401513480  :  0\n1/1 [==============================] - 0s 87ms/step\n8706369493133_275_0.jpg  :  8706369493133  :  0\n1/1 [==============================] - 0s 86ms/step\n3374949238822_296_0.jpg  :  3374949238822  :  0\n1/1 [==============================] - 0s 87ms/step\n5859350041547_210_0.jpg  :  5859350041547  :  0\n1/1 [==============================] - 0s 86ms/step\n6714761883294_297_0.jpg  :  6714761883294  :  0\n1/1 [==============================] - 0s 83ms/step\n9793174013105_114_0.jpg  :  9793174013105  :  0\n1/1 [==============================] - 0s 98ms/step\n6677093344812_226_0.jpg  :  6677093344812  :  0\n1/1 [==============================] - 0s 102ms/step\n3691861029643_190_0.jpg  :  3691861029643  :  0\n1/1 [==============================] - 0s 85ms/step\n3303839909115_159_0.jpg  :  3303839909115  :  0\n1/1 [==============================] - 0s 89ms/step\n7035614145260_34_0.jpg  :  7035614145260  :  0\n1/1 [==============================] - 0s 84ms/step\n4716063278701_154_0.jpg  :  4716063278701  :  0\n1/1 [==============================] - 0s 85ms/step\n6274229095336_71_0.jpg  :  6274229095336  :  0\n1/1 [==============================] - 0s 87ms/step\n1597126354715_205_0.jpg  :  1597126354715  :  0\n1/1 [==============================] - 0s 81ms/step\n2911354402984_109_0.jpg  :  2911354402984  :  0\n1/1 [==============================] - 0s 83ms/step\n5395158554686_20_0.jpg  :  5395158554686  :  0\n1/1 [==============================] - 0s 91ms/step\n2960291545704_115_0.jpg  :  2960291545704  :  0\n1/1 [==============================] - 0s 92ms/step\n8928265668303_220_0.jpg  :  8928265668303  :  0\n1/1 [==============================] - 0s 91ms/step\n9709564160045_176_0.jpg  :  9709564160045  :  0\n1/1 [==============================] - 0s 90ms/step\n7365830279990_7_0.jpg  :  7365830279990  :  0\n1/1 [==============================] - 0s 90ms/step\n7282857996450_179_0.jpg  :  7282857996450  :  0\n1/1 [==============================] - 0s 87ms/step\n9772630919526_161_0.jpg  :  9772630919526  :  0\n1/1 [==============================] - 0s 83ms/step\n7588406671343_52_0.jpg  :  7588406671343  :  0\n1/1 [==============================] - 0s 88ms/step\n5594967371532_75_0.jpg  :  5594967371532  :  0\n1/1 [==============================] - 0s 87ms/step\n8909186266410_276_0.jpg  :  8909186266410  :  0\n1/1 [==============================] - 0s 85ms/step\n4032699399666_112_0.jpg  :  4032699399666  :  0\n1/1 [==============================] - 0s 82ms/step\n2105556298289_60_0.jpg  :  2105556298289  :  0\n1/1 [==============================] - 0s 87ms/step\n8482213189475_218_0.jpg  :  8482213189475  :  0\n1/1 [==============================] - 0s 84ms/step\n4315995177290_125_0.jpg  :  4315995177290  :  0\n1/1 [==============================] - 0s 87ms/step\n2566618768575_185_0.jpg  :  2566618768575  :  0\n1/1 [==============================] - 0s 86ms/step\n6844154136536_28_0.jpg  :  6844154136536  :  0\n1/1 [==============================] - 0s 87ms/step\n6440155690727_10_0.jpg  :  6440155690727  :  0\n1/1 [==============================] - 0s 87ms/step\n9038026034441_200_0.jpg  :  9038026034441  :  0\n1/1 [==============================] - 0s 86ms/step\n8541702158313_110_0.jpg  :  8541702158313  :  0\n1/1 [==============================] - 0s 88ms/step\n3949676404774_2_0.jpg  :  3949676404774  :  0\n1/1 [==============================] - 0s 85ms/step\n7894813795924_187_0.jpg  :  7894813795924  :  0\n1/1 [==============================] - 0s 94ms/step\n1645744366778_173_0.jpg  :  1645744366778  :  0\n1/1 [==============================] - 0s 87ms/step\n1626744068817_166_0.jpg  :  1626744068817  :  0\n1/1 [==============================] - 0s 83ms/step\n5633507789410_237_0.jpg  :  5633507789410  :  0\n1/1 [==============================] - 0s 84ms/step\n3103934921124_149_0.jpg  :  3103934921124  :  0\n1/1 [==============================] - 0s 86ms/step\n6672765187247_155_0.jpg  :  6672765187247  :  0\n1/1 [==============================] - 0s 90ms/step\n6326392848605_264_0.jpg  :  6326392848605  :  0\n1/1 [==============================] - 0s 85ms/step\n8573416183381_35_0.jpg  :  8573416183381  :  0\n1/1 [==============================] - 0s 84ms/step\n2156680818393_89_0.jpg  :  2156680818393  :  0\n1/1 [==============================] - 0s 86ms/step\n1568919674365_106_0.jpg  :  1568919674365  :  0\n1/1 [==============================] - 0s 82ms/step\n5047930779076_222_0.jpg  :  5047930779076  :  0\n1/1 [==============================] - 0s 86ms/step\n5705868811960_169_0.jpg  :  5705868811960  :  0\n1/1 [==============================] - 0s 86ms/step\n1364749069957_82_0.jpg  :  1364749069957  :  0\n1/1 [==============================] - 0s 86ms/step\n8477474690983_1_0.jpg  :  8477474690983  :  0\n1/1 [==============================] - 0s 86ms/step\n1701208897643_88_0.jpg  :  1701208897643  :  0\n1/1 [==============================] - 0s 85ms/step\n5044598799606_77_0.jpg  :  5044598799606  :  0\n1/1 [==============================] - 0s 87ms/step\n4620612919390_101_0.jpg  :  4620612919390  :  0\n1/1 [==============================] - 0s 85ms/step\n4925899820460_231_0.jpg  :  4925899820460  :  0\n1/1 [==============================] - 0s 83ms/step\n8294349890039_97_0.jpg  :  8294349890039  :  0\n1/1 [==============================] - 0s 85ms/step\n8028019735029_224_0.jpg  :  8028019735029  :  0\n1/1 [==============================] - 0s 86ms/step\n9670842569891_273_0.jpg  :  9670842569891  :  0\n1/1 [==============================] - 0s 86ms/step\n2535762478012_198_0.jpg  :  2535762478012  :  0\n1/1 [==============================] - 0s 86ms/step\n3613334567889_193_0.jpg  :  3613334567889  :  0\n1/1 [==============================] - 0s 87ms/step\n2984092818188_134_0.jpg  :  2984092818188  :  0\n1/1 [==============================] - 0s 85ms/step\n4180054743002_202_0.jpg  :  4180054743002  :  0\n1/1 [==============================] - 0s 84ms/step\n2208091920919_111_0.jpg  :  2208091920919  :  0\n1/1 [==============================] - 0s 85ms/step\n9455224839584_70_0.jpg  :  9455224839584  :  0\n1/1 [==============================] - 0s 84ms/step\n6753695189027_80_0.jpg  :  6753695189027  :  0\n1/1 [==============================] - 0s 89ms/step\n5119652677968_194_0.jpg  :  5119652677968  :  0\n1/1 [==============================] - 0s 90ms/step\n1543080157091_44_0.jpg  :  1543080157091  :  0\n1/1 [==============================] - 0s 88ms/step\n2484886431116_18_0.jpg  :  2484886431116  :  0\n1/1 [==============================] - 0s 85ms/step\n2320398635423_186_0.jpg  :  2320398635423  :  0\n1/1 [==============================] - 0s 86ms/step\n9456486562111_157_0.jpg  :  9456486562111  :  0\n1/1 [==============================] - 0s 87ms/step\n2275381239938_16_0.jpg  :  2275381239938  :  0\n1/1 [==============================] - 0s 86ms/step\n7365477055544_54_0.jpg  :  7365477055544  :  0\n1/1 [==============================] - 0s 88ms/step\n4605950242423_3_0.jpg  :  4605950242423  :  0\n1/1 [==============================] - 0s 85ms/step\n4103169572190_188_0.jpg  :  4103169572190  :  0\n1/1 [==============================] - 0s 85ms/step\n5629484383970_287_0.jpg  :  5629484383970  :  0\n1/1 [==============================] - 0s 85ms/step\n1889436145511_67_0.jpg  :  1889436145511  :  0\n1/1 [==============================] - 0s 84ms/step\n4295212714456_146_0.jpg  :  4295212714456  :  0\n1/1 [==============================] - 0s 85ms/step\n5749643245557_4_0.jpg  :  5749643245557  :  0\n1/1 [==============================] - 0s 84ms/step\n1565244854370_76_0.jpg  :  1565244854370  :  0\n1/1 [==============================] - 0s 88ms/step\n2545240633444_242_0.jpg  :  2545240633444  :  0\n1/1 [==============================] - 0s 86ms/step\n5714484849509_192_0.jpg  :  5714484849509  :  0\n1/1 [==============================] - 0s 87ms/step\n5188491272191_278_0.jpg  :  5188491272191  :  0\n1/1 [==============================] - 0s 86ms/step\n8360137571210_74_0.jpg  :  8360137571210  :  0\n1/1 [==============================] - 0s 86ms/step\n6089709165566_61_0.jpg  :  6089709165566  :  0\n1/1 [==============================] - 0s 85ms/step\n3873752357107_212_0.jpg  :  3873752357107  :  0\n1/1 [==============================] - 0s 84ms/step\n1507227544861_19_0.jpg  :  1507227544861  :  0\n1/1 [==============================] - 0s 84ms/step\n8860293184694_201_0.jpg  :  8860293184694  :  0\n1/1 [==============================] - 0s 84ms/step\n6583455252735_15_0.jpg  :  6583455252735  :  0\n1/1 [==============================] - 0s 95ms/step\n9716308699105_69_0.jpg  :  9716308699105  :  0\n1/1 [==============================] - 0s 82ms/step\n4130160559905_211_0.jpg  :  4130160559905  :  0\n1/1 [==============================] - 0s 81ms/step\n3714404403349_213_0.jpg  :  3714404403349  :  0\n1/1 [==============================] - 0s 84ms/step\n7339782134959_124_0.jpg  :  7339782134959  :  0\n1/1 [==============================] - 0s 83ms/step\n5331865387407_175_0.jpg  :  5331865387407  :  0\n1/1 [==============================] - 0s 89ms/step\n3260262481017_78_0.jpg  :  3260262481017  :  0\n1/1 [==============================] - 0s 85ms/step\n4489040962794_23_0.jpg  :  4489040962794  :  0\n1/1 [==============================] - 0s 83ms/step\n9634148677421_62_0.jpg  :  9634148677421  :  0\n1/1 [==============================] - 0s 82ms/step\n2029992395244_147_0.jpg  :  2029992395244  :  0\n1/1 [==============================] - 0s 87ms/step\n7933338422653_280_0.jpg  :  7933338422653  :  0\n1/1 [==============================] - 0s 84ms/step\n8388458584375_72_0.jpg  :  8388458584375  :  0\n1/1 [==============================] - 0s 85ms/step\n8500652526627_165_0.jpg  :  8500652526627  :  0\n1/1 [==============================] - 0s 85ms/step\n7567606017687_266_0.jpg  :  7567606017687  :  0\n1/1 [==============================] - 0s 84ms/step\n5030435973513_84_0.jpg  :  5030435973513  :  0\n1/1 [==============================] - 0s 83ms/step\n5186391728343_184_0.jpg  :  5186391728343  :  0\n1/1 [==============================] - 0s 84ms/step\n2042946557321_223_0.jpg  :  2042946557321  :  0\n1/1 [==============================] - 0s 85ms/step\n4589498322925_26_0.jpg  :  4589498322925  :  0\n1/1 [==============================] - 0s 84ms/step\n5798007780685_12_0.jpg  :  5798007780685  :  0\n1/1 [==============================] - 0s 85ms/step\n5190977814764_153_0.jpg  :  5190977814764  :  0\n1/1 [==============================] - 0s 85ms/step\n3362749363271_235_0.jpg  :  3362749363271  :  0\n1/1 [==============================] - 0s 83ms/step\n5937625268667_152_0.jpg  :  5937625268667  :  0\n1/1 [==============================] - 0s 82ms/step\n5784304327098_196_0.jpg  :  5784304327098  :  0\n1/1 [==============================] - 0s 84ms/step\n9833290997313_206_0.jpg  :  9833290997313  :  0\n1/1 [==============================] - 0s 88ms/step\n5020458534167_249_0.jpg  :  5020458534167  :  0\n1/1 [==============================] - 0s 83ms/step\n5232775382226_219_0.jpg  :  5232775382226  :  0\n1/1 [==============================] - 0s 83ms/step\n6255458282209_135_0.jpg  :  6255458282209  :  0\n1/1 [==============================] - 0s 85ms/step\n2183342706477_11_0.jpg  :  2183342706477  :  0\n1/1 [==============================] - 0s 87ms/step\n4182322547558_120_0.jpg  :  4182322547558  :  0\n1/1 [==============================] - 0s 84ms/step\n1979836920860_248_0.jpg  :  1979836920860  :  0\n1/1 [==============================] - 0s 86ms/step\n7937555056905_259_0.jpg  :  7937555056905  :  0\n1/1 [==============================] - 0s 85ms/step\n3352809299732_85_0.jpg  :  3352809299732  :  0\n1/1 [==============================] - 0s 82ms/step\n6048972608385_260_0.jpg  :  6048972608385  :  0\n1/1 [==============================] - 0s 86ms/step\n5652741453987_228_0.jpg  :  5652741453987  :  0\n1/1 [==============================] - 0s 84ms/step\n4015641804180_31_0.jpg  :  4015641804180  :  0\n1/1 [==============================] - 0s 87ms/step\n5805355706462_293_0.jpg  :  5805355706462  :  0\n1/1 [==============================] - 0s 85ms/step\n5711439717678_172_0.jpg  :  5711439717678  :  0\n1/1 [==============================] - 0s 82ms/step\n1114082001233_63_0.jpg  :  1114082001233  :  0\n1/1 [==============================] - 0s 84ms/step\n3197806438148_227_0.jpg  :  3197806438148  :  0\n1/1 [==============================] - 0s 83ms/step\n4970722505519_247_0.jpg  :  4970722505519  :  0\n1/1 [==============================] - 0s 86ms/step\n1517641123450_83_0.jpg  :  1517641123450  :  0\n1/1 [==============================] - 0s 86ms/step\n5728494548024_133_0.jpg  :  5728494548024  :  0\n1/1 [==============================] - 0s 104ms/step\n3075587740745_160_0.jpg  :  3075587740745  :  0\n1/1 [==============================] - 0s 98ms/step\n8177015727160_216_0.jpg  :  8177015727160  :  0\n1/1 [==============================] - 0s 84ms/step\n6570434155477_91_0.jpg  :  6570434155477  :  0\n1/1 [==============================] - 0s 89ms/step\n6257935031775_6_0.jpg  :  6257935031775  :  0\n1/1 [==============================] - 0s 89ms/step\n2202231644697_262_0.jpg  :  2202231644697  :  0\n1/1 [==============================] - 0s 85ms/step\n5652115397725_286_0.jpg  :  5652115397725  :  0\n1/1 [==============================] - 0s 82ms/step\n7819162657099_291_0.jpg  :  7819162657099  :  0\n1/1 [==============================] - 0s 91ms/step\n2163926298765_49_0.jpg  :  2163926298765  :  0\n1/1 [==============================] - 0s 86ms/step\n5096008981569_51_0.jpg  :  5096008981569  :  0\n1/1 [==============================] - 0s 88ms/step\n5773517636042_53_0.jpg  :  5773517636042  :  0\n1/1 [==============================] - 0s 88ms/step\n6736812997484_163_0.jpg  :  6736812997484  :  0\n1/1 [==============================] - 0s 86ms/step\n2227055538694_105_0.jpg  :  2227055538694  :  0\n1/1 [==============================] - 0s 85ms/step\n3417383646607_42_0.jpg  :  3417383646607  :  0\n1/1 [==============================] - 0s 83ms/step\n8825325761854_207_0.jpg  :  8825325761854  :  0\n1/1 [==============================] - 0s 85ms/step\n1462227077354_238_0.jpg  :  1462227077354  :  0\n1/1 [==============================] - 0s 88ms/step\n1224454768067_158_0.jpg  :  1224454768067  :  0\n1/1 [==============================] - 0s 86ms/step\n4822361782502_92_0.jpg  :  4822361782502  :  0\n1/1 [==============================] - 0s 87ms/step\n2186680864243_277_0.jpg  :  2186680864243  :  0\n1/1 [==============================] - 0s 89ms/step\n9567016302234_38_0.jpg  :  9567016302234  :  0\n1/1 [==============================] - 0s 87ms/step\n1392894625087_93_0.jpg  :  1392894625087  :  0\n1/1 [==============================] - 0s 83ms/step\n2492667322331_239_0.jpg  :  2492667322331  :  0\n1/1 [==============================] - 0s 83ms/step\n2772020814117_164_0.jpg  :  2772020814117  :  0\n1/1 [==============================] - 0s 85ms/step\n7139008366702_143_0.jpg  :  7139008366702  :  0\n1/1 [==============================] - 0s 84ms/step\n9308609345128_245_0.jpg  :  9308609345128  :  0\n1/1 [==============================] - 0s 88ms/step\n6684675355548_263_0.jpg  :  6684675355548  :  0\n1/1 [==============================] - 0s 86ms/step\n1460869232711_252_0.jpg  :  1460869232711  :  0\n1/1 [==============================] - 0s 80ms/step\n3439366638287_141_0.jpg  :  3439366638287  :  0\n1/1 [==============================] - 0s 84ms/step\n2790656357181_209_0.jpg  :  2790656357181  :  0\n1/1 [==============================] - 0s 83ms/step\n5395952448235_265_0.jpg  :  5395952448235  :  0\n1/1 [==============================] - 0s 84ms/step\n2401283741228_5_0.jpg  :  2401283741228  :  0\n1/1 [==============================] - 0s 85ms/step\n9043493050252_284_0.jpg  :  9043493050252  :  0\n1/1 [==============================] - 0s 85ms/step\n4118761602244_178_0.jpg  :  4118761602244  :  0\n1/1 [==============================] - 0s 89ms/step\n1654291862916_81_0.jpg  :  1654291862916  :  0\n1/1 [==============================] - 0s 85ms/step\n8112197410011_17_0.jpg  :  8112197410011  :  0\n1/1 [==============================] - 0s 88ms/step\n3929317936734_295_0.jpg  :  3929317936734  :  0\n1/1 [==============================] - 0s 85ms/step\n5071867202611_232_0.jpg  :  5071867202611  :  0\n1/1 [==============================] - 0s 85ms/step\n5362234872712_250_0.jpg  :  5362234872712  :  0\n1/1 [==============================] - 0s 90ms/step\n9930076277116_21_0.jpg  :  9930076277116  :  0\n1/1 [==============================] - 0s 110ms/step\n7785799962250_289_0.jpg  :  7785799962250  :  0\n1/1 [==============================] - 0s 85ms/step\n9625161317333_208_0.jpg  :  9625161317333  :  0\n1/1 [==============================] - 0s 85ms/step\n4527980996575_108_0.jpg  :  4527980996575  :  0\n1/1 [==============================] - 0s 87ms/step\n3354396121823_246_0.jpg  :  3354396121823  :  0\n1/1 [==============================] - 0s 86ms/step\n1001371353893_253_0.jpg  :  1001371353893  :  0\n1/1 [==============================] - 0s 86ms/step\n7307405767945_86_0.jpg  :  7307405767945  :  0\n1/1 [==============================] - 0s 86ms/step\n7285176633693_96_0.jpg  :  7285176633693  :  0\n1/1 [==============================] - 0s 89ms/step\n3351074366651_113_0.jpg  :  3351074366651  :  0\n1/1 [==============================] - 0s 85ms/step\n2587511715626_132_0.jpg  :  2587511715626  :  0\n1/1 [==============================] - 0s 84ms/step\n7182021816969_79_0.jpg  :  7182021816969  :  0\n1/1 [==============================] - 0s 86ms/step\n3470851994105_290_0.jpg  :  3470851994105  :  0\n1/1 [==============================] - 0s 86ms/step\n3361649606990_27_0.jpg  :  3361649606990  :  0\n1/1 [==============================] - 0s 89ms/step\n4412531907479_142_0.jpg  :  4412531907479  :  0\n1/1 [==============================] - 0s 89ms/step\n8535652262091_126_0.jpg  :  8535652262091  :  0\n1/1 [==============================] - 0s 88ms/step\n4463118251690_150_0.jpg  :  4463118251690  :  0\n1/1 [==============================] - 0s 89ms/step\n8875691401267_48_0.jpg  :  8875691401267  :  0\n1/1 [==============================] - 0s 87ms/step\n4562191563147_168_0.jpg  :  4562191563147  :  0\n1/1 [==============================] - 0s 88ms/step\n7933411518907_66_0.jpg  :  7933411518907  :  0\n1/1 [==============================] - 0s 86ms/step\n8264300382545_137_0.jpg  :  8264300382545  :  0\n1/1 [==============================] - 0s 84ms/step\n3819825535430_104_0.jpg  :  3819825535430  :  0\n1/1 [==============================] - 0s 84ms/step\n8196718611569_119_0.jpg  :  8196718611569  :  0\n1/1 [==============================] - 0s 85ms/step\n7924655858935_138_0.jpg  :  7924655858935  :  0\n1/1 [==============================] - 0s 82ms/step\n1626826083622_24_0.jpg  :  1626826083622  :  0\n1/1 [==============================] - 0s 83ms/step\n8520847444499_204_0.jpg  :  8520847444499  :  0\n1/1 [==============================] - 0s 84ms/step\n2515268631128_274_0.jpg  :  2515268631128  :  0\n1/1 [==============================] - 0s 87ms/step\n3416867140488_270_0.jpg  :  3416867140488  :  0\n1/1 [==============================] - 0s 86ms/step\n7367251006322_32_0.jpg  :  7367251006322  :  0\n1/1 [==============================] - 0s 84ms/step\n4868146121531_57_0.jpg  :  4868146121531  :  0\n1/1 [==============================] - 0s 86ms/step\n2883789100288_180_0.jpg  :  2883789100288  :  0\n1/1 [==============================] - 0s 84ms/step\n5838845488418_177_0.jpg  :  5838845488418  :  0\n1/1 [==============================] - 0s 81ms/step\n3294364386222_267_0.jpg  :  3294364386222  :  0\n1/1 [==============================] - 0s 85ms/step\n3266917305981_298_0.jpg  :  3266917305981  :  0\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}