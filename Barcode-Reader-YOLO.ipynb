{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install python-barcode\n!pip install check-digit-EAN13","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Input, Conv2D, Add, ZeroPadding2D, UpSampling2D, Concatenate, MaxPooling2D, ZeroPadding2D, Lambda, Reshape, Flatten, Dense, concatenate\nfrom tensorflow.compat.v1.image import resize_nearest_neighbor, resize_bilinear\nfrom tensorflow.keras.layers import ReLU\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import MaxPool2D\nfrom tensorflow.keras.layers import Lambda\nfrom tensorflow.python.framework.ops import disable_eager_execution\nfrom tensorflow.keras.callbacks import *\nfrom functools import reduce\nfrom PIL import Image\nfrom matplotlib.colors import rgb_to_hsv, hsv_to_rgb\nimport cv2\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.utils import Sequence\nimport os \nimport cv2\nfrom barcode import EAN13, ISBN13\nfrom barcode.writer import ImageWriter\nfrom tqdm import tqdm\nfrom check_digit_EAN13.check_digit import get_check_digit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_HEIGHT = 160\nIMAGE_WIDTH = 320\nBATCH_SIZE = 128\ncount = 15000\npath = \"dataset_2\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists(os.path.join(path, \"with_numbers\", \"images\")):\n    os.makedirs(os.path.join(path, \"with_numbers\", \"images\"))\nif not os.path.exists(os.path.join(path, \"without_numbers\", \"images\")):\n    os.makedirs(os.path.join(path, \"without_numbers\", \"images\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in tqdm(range(count)):\n    random_code = np.random.randint(999999999999, 9999999999999, dtype=np.int64)\n    random_code = get_check_digit(random_code)\n    with open(\"{}/with_numbers/images/{}_{}_1.jpg\".format(path, str(random_code), str(i)), \"wb\") as file:\n        EAN13(str(random_code), writer=ImageWriter()).write(file)\n    # if i % 2 == 0:\n    image = cv2.imread(\"{}/with_numbers/images/{}_{}_1.jpg\".format(path, str(random_code), str(i)), cv2.IMREAD_GRAYSCALE)\n    image = np.asarray(image)[2:199, 63:460]\n    image = cv2.resize(image, (320, 160))\n    cv2.imwrite(\"{}/without_numbers/images/{}_{}_0.jpg\".format(path, str(random_code), str(i)), image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Datagenerator(Sequence):\n    def __init__(self, image_set_path, batch_size):\n        self.image_set_path = image_set_path\n        self.batch_size = batch_size\n        self.image_list = os.listdir(image_set_path)\n        print(len(self.image_list))\n\n    def __getitem__(self, index):\n        batch_input_list = self.image_list[self.batch_size * index: self.batch_size * (1 + index)]\n        \n        X = np.zeros((self.batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, 1))\n        Y = np.zeros((self.batch_size, 13, 10))\n        for i, image_name in enumerate(batch_input_list):\n            image = cv2.imread(os.path.join(self.image_set_path, image_name), cv2.IMREAD_GRAYSCALE)\n            image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n            image = np.expand_dims(image, -1)\n            image = image / 128\n            X[i] = image\n            Y[i] = self.encode_label(image_name.split(\"_\")[0])            \n        return X, Y\n\n    def __len__(self):\n        return len(self.image_list) // self.batch_size\n    \n    def encode_label(self, label):\n        OHE = np.zeros((13, 10))\n        for i, num in enumerate(label):\n            num = int(num)\n            OHE[i][num] = 1\n        return OHE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def custom_loss_tf(y_true, y_pred):\n    y_true = tf.reshape(y_true, (-1, 13, 10))\n    y_pred = tf.reshape(y_pred, (-1, 13, 10))\n    soft_pred = tf.math.softmax(y_pred, axis=-1)\n    cross_entropy = tf.losses.categorical_crossentropy(y_true=y_true, y_pred=soft_pred)\n    sum_loss = tf.math.reduce_sum(cross_entropy)\n    return sum_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Conv2D_block(inputs, out_channels, kernel_size=(1, 1), strides=(1, 1), padding=\"same\"):\n    conv = Conv2D(out_channels, kernel_size, strides=strides, padding=padding, use_bias=False)(inputs)\n    bn = BatchNormalization()(conv)\n    relu_out = ReLU()(bn)\n\n    return relu_out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Bottleneck(out_channels, shortcut=True, group=1, e=0.5, inputs=None):\n    if shortcut:\n        c_ = int(out_channels * e)\n        x1 = Conv2D_block(out_channels=c_, inputs=inputs)\n        x2 = Conv2D_block(out_channels=out_channels, inputs=x1, kernel_size=(3, 3), strides=(1, 1))\n        add = Add()([inputs, x2])\n        add = ReLU()(add)\n        return add\n    else:\n        c_ = int(out_channels * e)\n        x1 = Conv2D_block(out_channels=c_, inputs=inputs)\n        x2 = Conv2D_block(out_channels=out_channels, inputs=x1, kernel_size=(3, 3), strides=(1, 1))\n        return x2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def BottleneckCSP(out_channels, number=1, shortcut=True, group=1, e=0.5, inputs=None):\n    c_ = int(out_channels * e)\n    x1 = Conv2D_block(out_channels=c_, kernel_size=(1, 1), strides=(1, 1), inputs=inputs)\n\n    for _ in range(number):\n        x1 = Bottleneck(out_channels=c_, shortcut=shortcut, e=1.0, group=group, inputs=x1)\n    y2 = Conv2D_block(out_channels=c_, kernel_size=(1, 1), strides=(1, 1), inputs=inputs)\n\n    c = Concatenate()([x1, y2])\n    c = Conv2D_block(out_channels=2 * c_, kernel_size=(1, 1), strides=(1, 1), inputs=c)\n    return c","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def SPP(c1, c2, k=(5, 9, 13), inputs=None):\n    c_ = c1 // 2  \n    x = Conv2D_block(out_channels=c_, kernel_size=(1, 1), strides=(1, 1), inputs=inputs)\n    x = Conv2D_block(out_channels=c2, kernel_size=(1, 1), strides=(1, 1), inputs=x)\n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Dense_layer(num_class, inputs=None):\n    if len(inputs.shape) > 2:\n        inputs = Flatten()(inputs)\n\n    dense = Dense(num_class, activation=\"relu\")(inputs)\n\n    return dense","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _create_model():\n    input_layer = Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 1),\n                            name=\"input\")\n\n    x0 = Conv2D_block(inputs=input_layer, out_channels=16, kernel_size=(3,3), strides=(2, 2))\n    x1 = Conv2D_block(inputs=x0, out_channels=32, kernel_size=(3, 3), strides=(2, 2))\n    x2 = BottleneckCSP(inputs=x1, number=1, out_channels=32, shortcut=True, group=1, e=0.5)\n    x3 = Conv2D_block(inputs=x2, out_channels=64, kernel_size=(3, 3), strides=(2, 2))\n    x4 = BottleneckCSP(inputs=x3, number=2, out_channels=64, shortcut=True, group=1, e=0.5)\n    x5 = Conv2D_block(inputs=x4, out_channels=128, kernel_size=(3, 3), strides=(2, 2))\n    x6 = BottleneckCSP(inputs=x5, number=3, out_channels=128, shortcut=True, group=1, e=0.5)    \n    x7 = Conv2D_block(inputs=x6, out_channels=256, kernel_size=(3, 3), strides=(1, 1))\n    x9 = BottleneckCSP(inputs=x7, number=1, out_channels=256, shortcut=True, group=1, e=0.5)\n    x111 = SPP(64, 32, inputs=x9)\n\n    # block 1\n    x10 = Conv2D_block(inputs=x111, out_channels=32, kernel_size=(3, 3), strides=(2, 2))\n    x10 = Dense_layer(130, x10)\n    \n    model = Model(input_layer, x10)\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = _create_model()\nmodel.summary()\nmodel.compile(optimizer=\"adam\", loss=custom_loss_tf, metrics=custom_loss_tf, run_eagerly=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_generator = Datagenerator(\"/kaggle/working/dataset_2/without_numbers/images\", BATCH_SIZE) \ncallbacks_ckpt = ModelCheckpoint(\"model_{epoch:03d}.h5\", save_freq=10)\nimage_batch_shape = (BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, 1)\nlabel_batch_shape = (BATCH_SIZE, 13, 10)\ntf_train_generator = tf.data.Dataset.from_generator(lambda: map(tuple, data_generator), \n                                                    (tf.float32, tf.float32),\n                                                    (image_batch_shape, label_batch_shape))\ntf_train_generator = tf_train_generator.prefetch(buffer_size=tf.data.AUTOTUNE).cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.config.run_functions_eagerly(True)\nmodel.fit(tf_train_generator, epochs=500, callbacks=[callbacks_ckpt], verbose=1)\nmodel.save(\"last_model.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"test\"\nif not os.path.exists(os.path.join(\"test\", \"with_numbers\", \"images\")):\n    os.makedirs(os.path.join(\"test\", \"with_numbers\", \"images\"))\nif not os.path.exists(os.path.join(\"test\", \"without_numbers\", \"   images\")):\n    os.makedirs(os.path.join(\"test\", \"without_numbers\", \"images\"))\ncount = 300\nfor i in tqdm(range(count)):\n    random_code = np.random.randint(999999999999, 9999999999999, dtype=np.int64)\n    random_code = get_check_digit(random_code)\n    with open(\"{}/with_numbers/images/{}_{}_1.jpg\".format(path, str(random_code), str(i)), \"wb\") as file:\n        EAN13(str(random_code), writer=ImageWriter()).write(file)\n    # if i % 2 == 0:\n    image = cv2.imread(\"{}/with_numbers/images/{}_{}_1.jpg\".format(path, str(random_code), str(i)), cv2.IMREAD_GRAYSCALE)\n    image = np.asarray(image)[2:199, 63:460]\n    image = cv2.resize(image, (320, 160))\n    cv2.imwrite(\"{}/without_numbers/images/{}_{}_0.jpg\".format(path, str(random_code), str(i)), image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def filter_predicitons_tf(y_pred):\n    barcode_list = []\n    y_pred = np.reshape(y_pred, (-1, 13, 10))\n#     print(tf.make_ndarray(y_pred))\n    pred_idx = np.argmax(y_pred, axis=-1)\n    for pred_barcode in pred_idx:\n        barcode = \"\"\n        for num in pred_barcode:\n            barcode += str(num)\n        barcode_list.append(barcode)\n    return barcode_list\n\ndef humming_distance(string_1, string_2):\n    i = 0\n    count = 0\n    while i < len(string_1):\n        if string_1[i] != string_2[i]:\n            count += 1\n        i += 1\n    return count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_count = 0\nfor image_name in os.listdir(\"/kaggle/working/test/without_numbers/images\"):\n    image = cv2.imread(\"/kaggle/working/test/without_numbers/images/\"+ image_name, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n    image = np.expand_dims(image, -1)\n    image = image / 128\n    image = np.asarray([image])\n    res = model.predict([image])\n    res = filter_predicitons_tf(res)\n#     print(image_name.split(\"_\")[0], res[0])\n    dist = humming_distance(image_name.split(\"_\")[0], res[0])\n    if dist == 0:\n        res_count = res_count + 1\n    print(image_name, \" : \", res[0], \" : \", dist)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}